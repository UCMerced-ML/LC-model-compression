{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LC_algorithm_demo.ipynb","provenance":[],"collapsed_sections":["xxj7fpehFNAX","eQuLZemkIRXZ","_tT9Mdm-IT9w","jd9Y5YEKJCYh","08XSsmyEJG08"],"authorship_tag":"ABX9TyNB+peiDUkhXXW5jgRfb4LS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ysApKYweEtY_"},"source":["! git clone https://github.com/UCMerced-ML/LC-model-compression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4evE8fzBE5tx"},"source":["! pip3 install -e ./LC-model-compression"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZWghZ11EXAD"},"source":["## IMPORTANT!\n","At this point you need to restart the runtime by doing \"Runtim=>Restart Runtime\""]},{"cell_type":"code","metadata":{"id":"KUa0UHVaFId6"},"source":["import lc\n","from lc.torch import ParameterTorch as Param, AsVector, AsIs\n","from lc.compression_types import ConstraintL0Pruning, LowRank, RankSelection, AdaptiveQuantization\n","from lc.models.torch import lenet300_classic, lenet300_modern_drop, lenet300_modern\n","# from utils import compute_acc_loss\n","\n","import numpy as np\n","\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import TensorDataset, DataLoader\n","from torchvision import datasets\n","torch.set_num_threads(4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPBSdCKBGbRw"},"source":["def compute_acc_loss(forward_func, data_loader):\n","    correct_cnt, ave_loss = 0, 0\n","    for batch_idx, (x, target) in enumerate(data_loader):\n","        with torch.no_grad():\n","            target = target.cuda()\n","            score, loss = forward_func(x.cuda(), target)\n","            _, pred_label = torch.max(score.data, 1)\n","            correct_cnt += (pred_label == target.data).sum().item()\n","            ave_loss += loss.data.item() * len(x)\n","    accuracy = correct_cnt * 1.0 / len(data_loader.dataset)\n","    ave_loss /= len(data_loader.dataset)\n","    return accuracy, ave_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ullumXeERo6"},"source":["## Data\n","We use the MNIST dataset for this demo. The dataset containssubtracted 28x28 grayscale images with digits from 0 to 9. The images are normalized to have grayscale value 0 to 1 and then mean is subtracted."]},{"cell_type":"code","metadata":{"id":"zk8La6_4EkLE"},"source":["from matplotlib import pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","plt.rcParams['figure.figsize'] = [10, 5]\n","def show_MNIST_images():\n","    train_data_th = datasets.MNIST(root='./datasets', download=True, train=True)\n","    data_train = np.array(train_data_th.data[:])\n","    targets = np.array(train_data_th.targets)\n","    images_to_show = 5\n","    random_indexes = np.random.randint(data_train.shape[0], size=images_to_show)\n","    for i,ind in enumerate(random_indexes):\n","        plt.subplot(1,images_to_show,i+1)\n","        plt.imshow(data_train[ind], cmap='gray')\n","        plt.xlabel(targets[ind])\n","        plt.xticks([])\n","        plt.yticks([])\n","show_MNIST_images()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPxCPbyYEkqp"},"source":["def data_loader(batch_size=2048, n_workers=4):\n","    train_data_th = datasets.MNIST(root='./datasets', download=True, train=True)\n","    test_data_th = datasets.MNIST(root='./datasets', download=True, train=False)\n","\n","    data_train = np.array(train_data_th.data[:]).reshape([-1, 28 * 28]).astype(np.float32)\n","    data_test = np.array(test_data_th.data[:]).reshape([-1, 28 * 28]).astype(np.float32)\n","    data_train = (data_train / 255)\n","    dtrain_mean = data_train.mean(axis=0)\n","    data_train -= dtrain_mean\n","    data_test = (data_test / 255).astype(np.float32)\n","    data_test -= dtrain_mean\n","\n","    train_data = TensorDataset(torch.from_numpy(data_train), train_data_th.targets)\n","    test_data = TensorDataset(torch.from_numpy(data_test), test_data_th.targets)\n","\n","    train_loader = DataLoader(train_data, num_workers=n_workers, batch_size=batch_size, shuffle=True,)\n","    test_loader = DataLoader(test_data, num_workers=n_workers, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uhEPh4zCEvgO"},"source":["##Reference Network\n","We use cuda capable GPU for our experiments. The network has 3 fully-connected layers with dimensions 784x300, 300x100, and 100x10, and the total of 266200 parameters (which includes biases). The network was trained to have a test error of 1.79%, which is pretty decent result but not as low as you can get with convolutional neural networks.\n"]},{"cell_type":"code","metadata":{"id":"VvFBm7snEnqe"},"source":["device = torch.device('cuda') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVVvGuheE3wS"},"source":["def train_test_acc_eval_f(net):\n","    train_loader, test_loader = data_loader()\n","    def forward_func(x, target):\n","        y = net(x)\n","        return y, net.loss(y, target)\n","    acc_train, loss_train = compute_acc_loss(forward_func, train_loader)\n","    acc_test, loss_test = compute_acc_loss(forward_func, test_loader)\n","\n","    print(f\"Train err: {100-acc_train*100:.2f}%, train loss: {loss_train}\")\n","    print(f\"TEST ERR: {100-acc_test*100:.2f}%, test loss: {loss_test}\")\n","    \n","def load_reference_lenet300():\n","    net = lenet300_modern().to(device)\n","    # state_dict = torch.load('lenet300_modern_drop_wd.th')\n","    state_dict = torch.utils.model_zoo.load_url('https://ucmerced.box.com/shared/static/766axnc8qq429hiqqyqqo07ek46oqoxq.th')\n","    net.load_state_dict(state_dict)\n","    return net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FeA4mLF-E5Sw"},"source":["train_test_acc_eval_f(load_reference_lenet300().eval())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRouY3-VFJLB"},"source":["## Compression using the LC toolkit\n","### Step 1: L step\n","We will use same L step with same hyperparamters for all our compression examples"]},{"cell_type":"code","metadata":{"id":"RG5iJunyFB4j"},"source":["def my_l_step(model, lc_penalty, step):\n","    train_loader, test_loader = data_loader()\n","    params = list(filter(lambda p: p.requires_grad, model.parameters()))\n","    lr = 0.7*(0.98**step)\n","    optimizer = optim.SGD(params, lr=lr, momentum=0.9, nesterov=True)\n","    print(f'L-step #{step} with lr: {lr:.5f}')\n","    epochs_per_step_ = 7\n","    if step == 0:\n","        epochs_per_step_ = epochs_per_step_ * 2\n","    for epoch in range(epochs_per_step_):\n","        avg_loss = []\n","        for x, target in train_loader:\n","            optimizer.zero_grad()\n","            x = x.to(device)\n","            target = target.to(dtype=torch.long, device=device)\n","            out = model(x)\n","            loss = model.loss(out, target) + lc_penalty()\n","            avg_loss.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f\"\\tepoch #{epoch} is finished.\")\n","        print(f\"\\t  avg. train loss: {np.mean(avg_loss):.6f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xxj7fpehFNAX"},"source":["### Step 2: Schedule of mu values"]},{"cell_type":"code","metadata":{"id":"bmgVCpF_FLKc"},"source":["mu_s = [9e-5 * (1.1 ** n) for n in range(20)]\n","# 20 L-C steps in total\n","# total training epochs is 7 x 20 = 140"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eQuLZemkIRXZ"},"source":["### Compression time! Pruning\n","Let us prune all but 5% of the weights in the network (5% = 13310 weights)"]},{"cell_type":"code","metadata":{"id":"QXalSNwdFOcp"},"source":["net = load_reference_lenet300()\n","\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","compression_tasks = {\n","    Param(layers, device): (AsVector, ConstraintL0Pruning(kappa=13310), 'pruning')\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run()                              # entry point to the LC algorithm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_tT9Mdm-IT9w"},"source":["### Quantization\n","Now let us quantize each layer with its own codebook"]},{"cell_type":"code","metadata":{"id":"ndXQzWxcFQUs"},"source":["net = load_reference_lenet300()\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","\n","compression_tasks = {\n","    Param(layers[0], device): (AsVector, AdaptiveQuantization(k=2), 'layer0_quant'),\n","    Param(layers[1], device): (AsVector, AdaptiveQuantization(k=2), 'layer1_quant'),\n","    Param(layers[2], device): (AsVector, AdaptiveQuantization(k=2), 'layer2_quant')\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jd9Y5YEKJCYh"},"source":["### Mixing pruning, low rank, and quantization"]},{"cell_type":"code","metadata":{"id":"ReZIPzn3I8L8"},"source":["net = load_reference_lenet300()\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","\n","compression_tasks = {\n","    Param(layers[0], device): (AsVector, ConstraintL0Pruning(kappa=5000), 'pruning'),\n","    Param(layers[1], device): (AsIs, LowRank(target_rank=9, conv_scheme=None), 'low-rank'),\n","    Param(layers[2], device): (AsVector, AdaptiveQuantization(k=2), 'quant')\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"08XSsmyEJG08"},"source":["### Additive combination of Quantization and Pruning"]},{"cell_type":"code","metadata":{"id":"5nO4XSlpI-48"},"source":["net = load_reference_lenet300()\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","\n","compression_tasks = {\n","    Param(layers, device): [\n","        (AsVector, ConstraintL0Pruning(kappa=2662), 'pruning'),\n","        (AsVector, AdaptiveQuantization(k=2), 'quant')\n","    ]\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dj7OJM3jKqW6"},"source":["### Low-rank compression with automatic rank selection"]},{"cell_type":"code","metadata":{"id":"NyDPsLAVKq9X"},"source":["net = load_reference_lenet300()\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","alpha=1e-9\n","compression_tasks = {\n","    Param(layers[0], device): (AsIs, RankSelection(conv_scheme='scheme_1', alpha=alpha, criterion='storage', module=layers[0], normalize=True), \"layer1_lr\"),\n","    Param(layers[1], device): (AsIs, RankSelection(conv_scheme='scheme_1', alpha=alpha, criterion='storage', module=layers[1], normalize=True), \"layer2_lr\"),\n","    Param(layers[2], device): (AsIs, RankSelection(conv_scheme='scheme_1', alpha=alpha, criterion='storage', module=layers[2], normalize=True), \"layer3_lr\")\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3FIQ2WWAfGw"},"source":["### ScaledBinaryQuantization"]},{"cell_type":"code","metadata":{"id":"UeESVmskORN8"},"source":["from lc.compression_types import ScaledBinaryQuantization\n","net = load_reference_lenet300()\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","\n","compression_tasks = {\n","    Param(layers[0], device): (AsVector, ScaledBinaryQuantization(), 'layer0_quant'),\n","    Param(layers[1], device): (AsVector, ScaledBinaryQuantization(), 'layer1_quant'),\n","    Param(layers[2], device): (AsVector, ScaledBinaryQuantization(), 'layer2_quant')\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJlVuYlAAeqh"},"source":["### ScaledTernaryQuantization"]},{"cell_type":"code","metadata":{"id":"sWbz-VekApSw"},"source":["from lc.compression_types import ScaledTernaryQuantization\n","net = load_reference_lenet300()\n","layers = [lambda x=x: getattr(x, 'weight') for x in net.modules() if isinstance(x, nn.Linear)]\n","\n","compression_tasks = {\n","    Param(layers[0], device): (AsVector, ScaledTernaryQuantization(), 'layer0_quant'),\n","    Param(layers[1], device): (AsVector, ScaledTernaryQuantization(), 'layer1_quant'),\n","    Param(layers[2], device): (AsVector, ScaledTernaryQuantization(), 'layer2_quant')\n","}\n","\n","lc_alg = lc.Algorithm(\n","    model=net,                            # model to compress\n","    compression_tasks=compression_tasks,  # specifications of compression\n","    l_step_optimization=my_l_step,        # implementation of L-step\n","    mu_schedule=mu_s,                     # schedule of mu values\n","    evaluation_func=train_test_acc_eval_f # evaluation function\n",")\n","lc_alg.run()  "],"execution_count":null,"outputs":[]}]}